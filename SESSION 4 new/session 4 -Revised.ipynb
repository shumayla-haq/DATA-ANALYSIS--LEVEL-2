{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# SESSION 4 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["TOC:<br>\n","\n","1. Face Recognition Library<br>\n","    1.1 Overview of popular face recognition libraries<br>\n","    1.2 Introduction to face detection algorithms and techniques<br>\n","    1.3 Face Encoding<br>\n","    1.4 Face Recognition<br>\n","2. Revision of numpy<br>\n","3. Revision of Open CV<br>\n","4. Revision of pandas<br>\n","5. CSV in Data Analysis<br>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","### 1. Face Recognition Library:\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### 1.1 Overview of popular face recognition libraries:\n","\n","OpenCV: <br>\n","OpenCV is a widely-used computer vision library that provides various functionalities, including face detection and recognition. It has robust support for image and video processing, making it a popular choice for face recognition tasks.<br>\n","dlib: <br>\n","dlib is a C++ library with Python bindings that offers advanced face detection and recognition capabilities. It provides pre-trained models for face landmark detection and facial feature extraction, making it useful for various face analysis tasks.<br>\n","face_recognition:<br>\n","face_recognition is a high-level face recognition library built on top of dlib. It simplifies the face recognition process by providing a simple API for face detection, face encoding, and face comparison.<br>\n","#### Installation and setup of the chosen face recognition library:\n","\n","To install a specific face recognition library, you can use the following commands:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["OPENCV : \n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: opencv-python in c:\\users\\nazim_haque\\appdata\\roaming\\python\\python312\\site-packages (4.8.1.78)\n","Requirement already satisfied: numpy>=1.21.2 in c:\\users\\nazim_haque\\appdata\\roaming\\python\\python312\\site-packages (from opencv-python) (1.26.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["pip install opencv-python"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["dlib:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting dlibNote: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  error: subprocess-exited-with-error\n","  \n","  × Building wheel for dlib (pyproject.toml) did not run successfully.\n","  │ exit code: 1\n","  ╰─> [78 lines of output]\n","      running bdist_wheel\n","      running build\n","      running build_ext\n","      <string>:125: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n","      Building extension for Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n","      Invoking CMake setup: 'cmake C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-90_2t3rp\\dlib_d0506fe383804b17a01bc79a77eb40ec\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-90_2t3rp\\dlib_d0506fe383804b17a01bc79a77eb40ec\\build\\lib.win-amd64-cpython-311 -DPYTHON_EXECUTABLE=c:\\ProgramData\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-90_2t3rp\\dlib_d0506fe383804b17a01bc79a77eb40ec\\build\\lib.win-amd64-cpython-311 -A x64'\n","      -- Building for: NMake Makefiles\n","      CMake Error at CMakeLists.txt:5 (message):\n","      \n","      \n","      \n","        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","      \n","      \n","        You must use Visual Studio to build a python extension on windows.  If you\n","        are getting this error it means you have not installed Visual C++.  Note\n","        that there are many flavors of Visual Studio, like Visual Studio for C#\n","        development.  You need to install Visual Studio for C++.\n","      \n","      \n","        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","      \n","      \n","      \n","      \n","      -- Configuring incomplete, errors occurred!\n","      Traceback (most recent call last):\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n","          main()\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n","          json_out['return_val'] = hook(**hook_input['kwargs'])\n","                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 251, in build_wheel\n","          return _build_backend().build_wheel(wheel_directory, config_settings,\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 404, in build_wheel\n","          return self._build_with_temp_dir(\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 389, in _build_with_temp_dir\n","          self.run_setup()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n","          exec(code, locals())\n","        File \"<string>\", line 218, in <module>\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n","          return distutils.core.setup(**attrs)\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n","          return run_commands(dist)\n","                 ^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n","          dist.run_commands()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n","          self.run_command(cmd)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 368, in run\n","          self.run_command(\"build\")\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n","          self.distribution.run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n","          self.run_command(cmd_name)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n","          self.distribution.run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-lgtipirv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"<string>\", line 130, in run\n","        File \"<string>\", line 167, in build_extension\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 413, in check_call\n","          raise CalledProcessError(retcode, cmd)\n","      subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-90_2t3rp\\\\dlib_d0506fe383804b17a01bc79a77eb40ec\\\\tools\\\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-90_2t3rp\\\\dlib_d0506fe383804b17a01bc79a77eb40ec\\\\build\\\\lib.win-amd64-cpython-311', '-DPYTHON_EXECUTABLE=c:\\\\ProgramData\\\\anaconda3\\\\python.exe', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-90_2t3rp\\\\dlib_d0506fe383804b17a01bc79a77eb40ec\\\\build\\\\lib.win-amd64-cpython-311', '-A', 'x64']' returned non-zero exit status 1.\n","      [end of output]\n","  \n","  note: This error originates from a subprocess, and is likely not a problem with pip.\n","  ERROR: Failed building wheel for dlib\n","ERROR: Could not build wheels for dlib, which is required to install pyproject.toml-based projects\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Downloading dlib-19.24.2.tar.gz (11.8 MB)\n","     ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n","     --------------------------------------- 0.0/11.8 MB 145.2 kB/s eta 0:01:21\n","     --------------------------------------- 0.0/11.8 MB 150.6 kB/s eta 0:01:18\n","     - -------------------------------------- 0.4/11.8 MB 1.4 MB/s eta 0:00:09\n","     ------- -------------------------------- 2.2/11.8 MB 6.9 MB/s eta 0:00:02\n","     --------------- ------------------------ 4.5/11.8 MB 12.5 MB/s eta 0:00:01\n","     ------------------------ --------------- 7.2/11.8 MB 17.7 MB/s eta 0:00:01\n","     --------------------------------- ----- 10.1/11.8 MB 22.3 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.6/11.8 MB 50.4 MB/s eta 0:00:01\n","     --------------------------------------  11.8/11.8 MB 21.1 MB/s eta 0:00:01\n","     --------------------------------------- 11.8/11.8 MB 18.7 MB/s eta 0:00:00\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Building wheels for collected packages: dlib\n","  Building wheel for dlib (pyproject.toml): started\n","  Building wheel for dlib (pyproject.toml): finished with status 'error'\n","Failed to build dlib\n"]}],"source":["pip install dlib"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["face_recognition:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting face-recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0 (from face-recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","     ---------------------------------------- 0.0/100.1 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/100.1 MB ? eta -:--:--\n","     -------------------------------------- 0.0/100.1 MB 653.6 kB/s eta 0:02:34\n","     ---------------------------------------- 0.3/100.1 MB 3.2 MB/s eta 0:00:32\n","      -------------------------------------- 2.5/100.1 MB 17.9 MB/s eta 0:00:06\n","     - ------------------------------------- 4.8/100.1 MB 25.7 MB/s eta 0:00:04\n","     -- ------------------------------------ 7.4/100.1 MB 31.6 MB/s eta 0:00:03\n","     --- ---------------------------------- 10.3/100.1 MB 54.4 MB/s eta 0:00:02\n","     ---- --------------------------------- 12.1/100.1 MB 54.4 MB/s eta 0:00:02\n","     ----- -------------------------------- 13.6/100.1 MB 50.4 MB/s eta 0:00:02\n","     ------ ------------------------------- 15.8/100.1 MB 50.4 MB/s eta 0:00:02\n","     ------ ------------------------------- 17.2/100.1 MB 43.7 MB/s eta 0:00:02\n","     ------- ------------------------------ 18.6/100.1 MB 38.5 MB/s eta 0:00:03\n","     ------- ------------------------------ 19.7/100.1 MB 36.4 MB/s eta 0:00:03\n","     ------- ------------------------------ 20.9/100.1 MB 32.7 MB/s eta 0:00:03\n","     -------- ----------------------------- 22.3/100.1 MB 29.8 MB/s eta 0:00:03\n","     -------- ----------------------------- 23.2/100.1 MB 28.5 MB/s eta 0:00:03\n","     --------- ---------------------------- 24.1/100.1 MB 27.3 MB/s eta 0:00:03\n","     --------- ---------------------------- 25.4/100.1 MB 24.2 MB/s eta 0:00:04\n","     --------- ---------------------------- 26.3/100.1 MB 22.6 MB/s eta 0:00:04\n","     ---------- --------------------------- 28.5/100.1 MB 23.4 MB/s eta 0:00:04\n","     ----------- -------------------------- 30.7/100.1 MB 26.2 MB/s eta 0:00:03\n","     ------------ ------------------------- 32.0/100.1 MB 26.2 MB/s eta 0:00:03\n","     ------------ ------------------------- 33.8/100.1 MB 31.1 MB/s eta 0:00:03\n","     ------------- ------------------------ 34.6/100.1 MB 31.2 MB/s eta 0:00:03\n","     ------------- ------------------------ 35.1/100.1 MB 28.5 MB/s eta 0:00:03\n","     ------------- ------------------------ 35.5/100.1 MB 26.2 MB/s eta 0:00:03\n","     ------------- ------------------------ 35.8/100.1 MB 24.2 MB/s eta 0:00:03\n","     ------------- ------------------------ 36.2/100.1 MB 23.4 MB/s eta 0:00:03\n","     ------------- ------------------------ 36.6/100.1 MB 23.4 MB/s eta 0:00:03\n","     -------------- ----------------------- 37.0/100.1 MB 21.1 MB/s eta 0:00:03\n","     -------------- ----------------------- 37.5/100.1 MB 19.8 MB/s eta 0:00:04\n","     -------------- ----------------------- 38.1/100.1 MB 18.7 MB/s eta 0:00:04\n","     -------------- ----------------------- 38.7/100.1 MB 17.7 MB/s eta 0:00:04\n","     -------------- ----------------------- 39.4/100.1 MB 16.4 MB/s eta 0:00:04\n","     --------------- ---------------------- 40.3/100.1 MB 15.2 MB/s eta 0:00:04\n","     --------------- ---------------------- 41.1/100.1 MB 14.9 MB/s eta 0:00:04\n","     --------------- ---------------------- 41.8/100.1 MB 14.6 MB/s eta 0:00:05\n","     ---------------- --------------------- 42.6/100.1 MB 13.9 MB/s eta 0:00:05\n","     ---------------- --------------------- 43.3/100.1 MB 13.6 MB/s eta 0:00:05\n","     ---------------- --------------------- 43.9/100.1 MB 13.1 MB/s eta 0:00:05\n","     ----------------- -------------------- 45.1/100.1 MB 13.4 MB/s eta 0:00:05\n","     ----------------- -------------------- 46.0/100.1 MB 14.9 MB/s eta 0:00:04\n","     ----------------- -------------------- 46.7/100.1 MB 15.6 MB/s eta 0:00:04\n","     ------------------ ------------------- 47.7/100.1 MB 16.8 MB/s eta 0:00:04\n","     ------------------ ------------------- 48.3/100.1 MB 17.2 MB/s eta 0:00:04\n","     ------------------ ------------------- 49.5/100.1 MB 18.2 MB/s eta 0:00:03\n","     ------------------- ------------------ 50.4/100.1 MB 19.3 MB/s eta 0:00:03\n","     ------------------- ------------------ 51.5/100.1 MB 19.3 MB/s eta 0:00:03\n","     ------------------- ------------------ 52.5/100.1 MB 19.2 MB/s eta 0:00:03\n","     -------------------- ----------------- 53.6/100.1 MB 20.5 MB/s eta 0:00:03\n","     -------------------- ----------------- 54.8/100.1 MB 21.1 MB/s eta 0:00:03\n","     --------------------- ---------------- 56.0/100.1 MB 21.9 MB/s eta 0:00:03\n","     --------------------- ---------------- 57.1/100.1 MB 23.4 MB/s eta 0:00:02\n","     ---------------------- --------------- 58.3/100.1 MB 24.3 MB/s eta 0:00:02\n","     ---------------------- --------------- 59.9/100.1 MB 24.2 MB/s eta 0:00:02\n","     ----------------------- -------------- 61.0/100.1 MB 25.2 MB/s eta 0:00:02\n","     ----------------------- -------------- 62.3/100.1 MB 26.2 MB/s eta 0:00:02\n","     ------------------------ ------------- 63.7/100.1 MB 27.3 MB/s eta 0:00:02\n","     ------------------------ ------------- 65.1/100.1 MB 28.5 MB/s eta 0:00:02\n","     ------------------------ ------------- 65.8/100.1 MB 27.3 MB/s eta 0:00:02\n","     ------------------------- ------------ 66.4/100.1 MB 24.2 MB/s eta 0:00:02\n","     ------------------------- ------------ 67.5/100.1 MB 24.2 MB/s eta 0:00:02\n","     -------------------------- ----------- 68.7/100.1 MB 23.4 MB/s eta 0:00:02\n","     -------------------------- ----------- 70.2/100.1 MB 24.2 MB/s eta 0:00:02\n","     --------------------------- ---------- 71.6/100.1 MB 25.1 MB/s eta 0:00:02\n","     --------------------------- ---------- 72.6/100.1 MB 24.2 MB/s eta 0:00:02\n","     ---------------------------- --------- 74.1/100.1 MB 24.3 MB/s eta 0:00:02\n","     ---------------------------- --------- 75.5/100.1 MB 24.2 MB/s eta 0:00:02\n","     ----------------------------- -------- 76.5/100.1 MB 27.3 MB/s eta 0:00:01\n","     ----------------------------- -------- 77.5/100.1 MB 26.2 MB/s eta 0:00:01\n","     ------------------------------ ------- 79.2/100.1 MB 27.3 MB/s eta 0:00:01\n","     ------------------------------ ------- 80.3/100.1 MB 28.5 MB/s eta 0:00:01\n","     ------------------------------- ------ 81.8/100.1 MB 28.4 MB/s eta 0:00:01\n","     ------------------------------- ------ 83.2/100.1 MB 28.4 MB/s eta 0:00:01\n","     ------------------------------- ------ 83.6/100.1 MB 26.2 MB/s eta 0:00:01\n","     ------------------------------- ------ 84.2/100.1 MB 25.1 MB/s eta 0:00:01\n","     -------------------------------- ----- 84.7/100.1 MB 23.4 MB/s eta 0:00:01\n","     -------------------------------- ----- 85.2/100.1 MB 21.9 MB/s eta 0:00:01\n","     -------------------------------- ----- 85.6/100.1 MB 19.9 MB/s eta 0:00:01\n","     -------------------------------- ----- 86.1/100.1 MB 20.5 MB/s eta 0:00:01\n","     -------------------------------- ----- 86.6/100.1 MB 19.3 MB/s eta 0:00:01\n","     --------------------------------- ---- 87.1/100.1 MB 18.7 MB/s eta 0:00:01\n","     --------------------------------- ---- 87.7/100.1 MB 17.7 MB/s eta 0:00:01\n","     --------------------------------- ---- 88.5/100.1 MB 17.2 MB/s eta 0:00:01\n","     --------------------------------- ---- 89.3/100.1 MB 16.4 MB/s eta 0:00:01\n","     ---------------------------------- --- 90.3/100.1 MB 15.6 MB/s eta 0:00:01\n","     ---------------------------------- --- 91.2/100.1 MB 15.2 MB/s eta 0:00:01\n","     ---------------------------------- --- 92.1/100.1 MB 14.9 MB/s eta 0:00:01\n","     ----------------------------------- -- 93.0/100.1 MB 14.6 MB/s eta 0:00:01\n","     ----------------------------------- -- 93.8/100.1 MB 14.6 MB/s eta 0:00:01\n","     ----------------------------------- -- 94.6/100.1 MB 14.9 MB/s eta 0:00:01\n","     ------------------------------------ - 95.4/100.1 MB 15.2 MB/s eta 0:00:01\n","     ------------------------------------ - 96.0/100.1 MB 16.4 MB/s eta 0:00:01\n","     ------------------------------------ - 96.9/100.1 MB 16.8 MB/s eta 0:00:01\n","     -------------------------------------  97.8/100.1 MB 16.8 MB/s eta 0:00:01\n","     -------------------------------------  99.0/100.1 MB 17.7 MB/s eta 0:00:01\n","     -------------------------------------  99.7/100.1 MB 17.7 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     ------------------------------------  100.1/100.1 MB 18.2 MB/s eta 0:00:01\n","     -------------------------------------- 100.1/100.1 MB 8.4 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: Click>=6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (8.0.4)\n","Collecting dlib>=19.7 (from face-recognition)\n","  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (1.24.3)\n","Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from face-recognition) (9.4.0)\n","Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from Click>=6.0->face-recognition) (0.4.6)\n","Building wheels for collected packages: dlib, face-recognition-models\n","  Building wheel for dlib (pyproject.toml): started\n","  Building wheel for dlib (pyproject.toml): finished with status 'error'\n","  Building wheel for face-recognition-models (setup.py): started\n","  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=47984ba32f10bc5a101114a33ed0168e5fb1142bc43fcdccef1e764db7ca8da6\n","  Stored in directory: c:\\users\\nazim_haque\\appdata\\local\\pip\\cache\\wheels\\04\\52\\ec\\9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n","Successfully built face-recognition-models\n","Failed to build dlib\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  error: subprocess-exited-with-error\n","  \n","  × Building wheel for dlib (pyproject.toml) did not run successfully.\n","  │ exit code: 1\n","  ╰─> [78 lines of output]\n","      running bdist_wheel\n","      running build\n","      running build_ext\n","      <string>:125: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n","      Building extension for Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n","      Invoking CMake setup: 'cmake C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-nit_79nx\\dlib_31bdb6add55c4b939309d49d1c57370a\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-nit_79nx\\dlib_31bdb6add55c4b939309d49d1c57370a\\build\\lib.win-amd64-cpython-311 -DPYTHON_EXECUTABLE=c:\\ProgramData\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-install-nit_79nx\\dlib_31bdb6add55c4b939309d49d1c57370a\\build\\lib.win-amd64-cpython-311 -A x64'\n","      -- Building for: NMake Makefiles\n","      CMake Error at CMakeLists.txt:5 (message):\n","      \n","      \n","      \n","        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","      \n","      \n","        You must use Visual Studio to build a python extension on windows.  If you\n","        are getting this error it means you have not installed Visual C++.  Note\n","        that there are many flavors of Visual Studio, like Visual Studio for C#\n","        development.  You need to install Visual Studio for C++.\n","      \n","      \n","        !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","      \n","      \n","      \n","      \n","      -- Configuring incomplete, errors occurred!\n","      Traceback (most recent call last):\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n","          main()\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n","          json_out['return_val'] = hook(**hook_input['kwargs'])\n","                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 251, in build_wheel\n","          return _build_backend().build_wheel(wheel_directory, config_settings,\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 404, in build_wheel\n","          return self._build_with_temp_dir(\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 389, in _build_with_temp_dir\n","          self.run_setup()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n","          exec(code, locals())\n","        File \"<string>\", line 218, in <module>\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n","          return distutils.core.setup(**attrs)\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n","          return run_commands(dist)\n","                 ^^^^^^^^^^^^^^^^^^\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n","          dist.run_commands()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n","          self.run_command(cmd)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 368, in run\n","          self.run_command(\"build\")\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n","          self.distribution.run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\n","          self.run_command(cmd_name)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n","          self.distribution.run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n","          super().run_command(command)\n","        File \"C:\\Users\\Nazim_HAQUE\\AppData\\Local\\Temp\\pip-build-env-obgo6c26\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n","          cmd_obj.run()\n","        File \"<string>\", line 130, in run\n","        File \"<string>\", line 167, in build_extension\n","        File \"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 413, in check_call\n","          raise CalledProcessError(retcode, cmd)\n","      subprocess.CalledProcessError: Command '['cmake', 'C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-nit_79nx\\\\dlib_31bdb6add55c4b939309d49d1c57370a\\\\tools\\\\python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-nit_79nx\\\\dlib_31bdb6add55c4b939309d49d1c57370a\\\\build\\\\lib.win-amd64-cpython-311', '-DPYTHON_EXECUTABLE=c:\\\\ProgramData\\\\anaconda3\\\\python.exe', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\\\Users\\\\Nazim_HAQUE\\\\AppData\\\\Local\\\\Temp\\\\pip-install-nit_79nx\\\\dlib_31bdb6add55c4b939309d49d1c57370a\\\\build\\\\lib.win-amd64-cpython-311', '-A', 'x64']' returned non-zero exit status 1.\n","      [end of output]\n","  \n","  note: This error originates from a subprocess, and is likely not a problem with pip.\n","  ERROR: Failed building wheel for dlib\n","ERROR: Could not build wheels for dlib, which is required to install pyproject.toml-based projects\n"]}],"source":["pip install face-recognition"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Introduction to the library's features and capabilities:\n","Each face recognition library offers different features and capabilities. Here's a brief overview of what you can expect from each library:\n","\n","OpenCV: OpenCV provides functions for face detection using Haar cascades or deep learning models. It also offers utilities for face recognition, such as Eigenfaces and Fisherfaces, and the ability to train custom models.\n","\n","dlib: dlib offers state-of-the-art face detection and recognition algorithms. It provides pre-trained models for face landmark detection, facial feature extraction, and face recognition. It also supports face clustering and face alignment.\n","\n","face_recognition: face_recognition library simplifies face recognition tasks by providing a high-level API. It utilizes dlib's face recognition models for face detection, encoding, and comparison. It allows you to compare faces, identify faces in images, and perform facial feature extraction.\n","\n","face_recognition: face_recognition library simplifies face recognition tasks by providing a high-level API. It utilizes dlib's face recognition models for face detection, encoding, and comparison. It allows you to compare faces, identify faces in images, and perform facial feature extraction.face_recognition: face_recognition library simplifies face recognition tasks by providing a high-level API. It utilizes dlib's face recognition models for face detection, encoding, and comparison. It allows you to compare faces, identify faces in images, and perform facial feature extraction.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","####  1.2 Introduction to face detection algorithms and techniques:\n","Face detection is a fundamental task in computer vision that involves locating and identifying faces within an image or video. Several algorithms and techniques have been developed for this purpose. Here are some commonly used ones:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Haar cascades: Haar cascades are a machine learning-based face detection algorithm. They use a cascade of simple classifiers trained on Haar-like features to detect faces. Haar-like features are rectangular regions with specific intensity patterns, such as edges and gradients. Haar cascades are fast and efficient, making them suitable for real-time face detection."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Deep learning-based detectors: Deep learning approaches have achieved significant advancements in face detection. These methods employ convolutional neural networks (CNNs) to learn discriminative features and make accurate predictions. Popular deep learning-based face detectors include the Single Shot Multibox Detector (SSD) and the You Only Look Once (YOLO) algorithm. These detectors offer higher accuracy but may be computationally more expensive."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Understanding the Haar cascades algorithm and its implementation using OpenCV:\n","Haar cascades algorithm can be implemented using the OpenCV library. Here's an example of using Haar cascades for face detection:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cv2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the pre-trained Haar cascade XML file"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the input image"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["image = cv2.imread('C:\\\\Users\\\\Nazim_HAQUE\\\\Downloads\\\\DATA-ANALYSIS -LEVEL-2-20231202T102458Z-001\\\\DATA-ANALYSIS -LEVEL-2\\\\SESSION 4 new\\\\Images\\\\input_image.jpg')\n","\n","# Display the image in a window\n","#cv2.imshow('Window Name', image)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert the image to grayscale"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Perform face detection"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Draw bounding boxes around the detected faces"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["for (x, y, w, h) in faces:\n","    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Display the result"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["cv2.imshow('Face Detection', image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Utilizing deep learning-based face detectors like the SSD or YOLO algorithm: \n","Deep learning-based face detectors, such as SSD and YOLO, provide higher accuracy compared to Haar cascades but require more computational resources. Here's an example of using the SSD face detector with OpenCV's DNN module:"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import cv2"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the pre-trained SSD model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"error","evalue":"OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromCaffe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeploy.prototxt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweights.caffemodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"]}],"source":["model = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'weights.caffemodel')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the input image"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["image = cv2.imread('Images/input_image.jpg')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Preprocess the image"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB=True, crop=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Set the input to the network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.setInput(blob)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Perform face detection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["detections = model.forward()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Process the detections"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","    if confidence > 0.5:  # Set a confidence threshold\n","        box = detections[0, 0, i, 3:7] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])\n","        (startX, startY, endX, endY) = box.astype(int)\n","        cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Display the result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cv2.imshow('Face Detection', image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Handling face detection in images and videos:\n","Both Haar cascades and deep learning-based detectors can handle face detection in images and videos. For images, you can directly apply the detection algorithm on each frame. For videos, you can process each frame in a loop to achieve real-time face detection. The OpenCV library provides functions for reading frames from video files or capturing frames from a camera."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Performance considerations and optimization techniques for face detection:\n","To optimize face detection performance, consider the following techniques:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Hardware acceleration: Utilize hardware resources like GPUs to speed up face detection algorithms, especially deep learning-based detectors."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Region of Interest (ROI): Limit the search space by specifying a region of interest where faces are likely to appear, instead of applying detection on the entire image or frame."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Multi-scale detection: Perform face detection at multiple scales to handle faces of different sizes. Use the scaleFactor parameter in OpenCV's face detection functions to control the scale factor."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Non-maximum suppression: Apply non-maximum suppression to remove redundant or overlapping detections and keep only the most confident face bounding boxes."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Model optimization: For deep learning-based detectors, optimize the model architecture and parameters to balance accuracy and speed. Techniques like model quantization and pruning can reduce the model size and inference time."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["These techniques can help improve the speed and efficiency of face detection algorithms in real-world scenarios."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### 1.3 Face Encoding:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Overview of face encoding and feature extraction methods:\n","Face encoding, also known as face embedding, is the process of representing a face as a numerical feature vector. This feature vector captures the unique characteristics of a face and can be used for various face recognition tasks. Here's an overview of face encoding methods:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Geometric-based methods: These methods analyze the geometric properties and spatial relationships between facial landmarks or key points. Features such as distances, angles, or ratios are extracted based on these properties. Statistical models like Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA) can be applied to further reduce the dimensionality of the features."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Deep learning-based methods: Deep learning approaches have demonstrated remarkable success in face encoding. These methods utilize deep neural networks to directly learn discriminative features from raw face images. By leveraging the power of convolutional neural networks (CNNs), deep learning-based face encoders can capture complex patterns and variations in face appearance."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Introduction to facial landmarks detection and its importance in face encoding:\n","Facial landmarks detection involves identifying key points on a face, such as the corners of the eyes, nose, and mouth. It is important in face encoding because:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Alignment: Facial landmarks can be used to align faces to a standardized pose. By aligning faces, variations due to head pose or facial expression can be minimized, resulting in more accurate feature extraction."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Region of Interest (ROI) selection: Facial landmarks provide information about the structure and shape of a face. They can be used to define a specific region of interest, such as the eyes or mouth, for extracting relevant features."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Using facial landmarks to align faces for accurate feature extraction:\n","To align faces using facial landmarks, you can follow these steps:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Detect facial landmarks using a facial landmarks detection algorithm. Popular libraries like dlib and OpenCV provide pre-trained models for this purpose."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Select specific facial landmarks that define the alignment transformation. For example, you can use the corners of the eyes or the tip of the nose."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Calculate the transformation parameters, such as rotation, translation, and scaling, based on the selected landmarks."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Apply the calculated transformation to align the face to a standardized pose."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Introduction to deep learning-based face encoders like FaceNet, ArcFace, or dlib:\n","Deep learning-based face encoders are powerful methods for extracting face embeddings. Here are brief introductions to some popular face encoding algorithms:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["FaceNet: FaceNet is a deep learning-based face recognition model that learns a 128-dimensional embedding for each face. It uses a triplet loss function during training to optimize the embedding space, ensuring that the embeddings of the same person are close together while those of different people are far apart."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ArcFace: ArcFace is a state-of-the-art deep learning-based face recognition model that introduces an angular margin to the traditional softmax loss. This margin-based loss function enhances the discriminative power of the learned embeddings."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["dlib: The dlib library provides a pre-trained face recognition model that combines deep learning with geometric-based alignment. It computes a 128-dimensional face embedding using a neural network trained on a large dataset."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Extracting facial embeddings or feature vectors using the chosen face encoding algorithm:\n","To extract facial embeddings using a chosen face encoding algorithm, you can follow these steps:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Detect and align the face using facial landmarks detection techniques.\n","Preprocess the aligned face image, such as resizing and normalization, to match the requirements of the face encoding model."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Pass the preprocessed face image through the face encoding model to obtain the face embedding. The output will be a high-dimensional feature vector that represents the unique characteristics of the face."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Store the extracted face embeddings in a database or use them for face recognition tasks, such as face identification or verification."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here's an example of extracting facial embeddings using the dlib library:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'dlib'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"]}],"source":["import dlib\n","import numpy as np"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the pre-trained face recognition model from dlib"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["facerec_model = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the input image and detect facial landmarks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image = dlib.load_rgb_image(\"Images/input_image.jpg\")\n","face_landmarks = dlib.face_landmarks(image)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Compute the face embedding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_embedding = facerec_model.compute_face_descriptor(image, face_landmarks[0])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert the face embedding to a numpy array"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_embedding_np = np.array(face_embedding)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Print the face embedding"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["print(face_embedding_np)\n","This code utilizes the dlib library to detect facial landmarks and compute the face embedding using the pre-trained face recognition model. The resulting face embedding is then converted to a numpy array for further processing or storage."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Note: The specific implementation may vary depending on the chosen face encoding library or model. Please refer to the documentation and API of the respective library for detailed instructions on extracting facial embeddings using their provided models."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### 1.4 Face Recognition:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Understanding the concept of face recognition and its applications:\n","Face recognition is a technology that identifies or verifies individuals by analyzing and comparing their facial features. It has various applications, including:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Access control: Face recognition can be used for secure authentication and access control in systems such as door entry systems or mobile devices."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Surveillance: Face recognition can aid in identifying individuals in surveillance videos or images, assisting law enforcement agencies in criminal investigations."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Personalization: Face recognition can enable personalized experiences in applications like social media, e-commerce, or personalized advertising."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Creating a face recognition pipeline using the selected face recognition library:\n","To create a face recognition pipeline using a chosen face recognition library, you can follow these steps:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Gather a labeled dataset: Collect a dataset of face images with corresponding labels or identities."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Preprocess the images: Perform necessary preprocessing steps, such as face detection, alignment, resizing, and normalization, to ensure consistent input for the face recognition model."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Train a face recognition model: Utilize the labeled dataset to train a face recognition model. This involves extracting facial features or embeddings and training a classifier or distance-based algorithm for identification or verification."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Implement face identification: Create a function that takes an input face image and compares it with the known faces in the database to identify the person."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Implement face verification: Develop a function that takes an input face image and a claimed identity and determines if the face matches the claimed identity."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Training a face recognition model with a labeled dataset:\n","Here's an example of training a face recognition model using the face_recognition library in Python:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import face_recognition"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Path to the labeled dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_path = \"path/to/dataset\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_paths = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path)]\n","known_encodings = []\n","labels = []"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Extract face encodings and labels from the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for image_path in image_paths:\n","    image = face_recognition.load_image_file(image_path)\n","    encoding = face_recognition.face_encodings(image)[0]  # Assuming a single face in each image\n","    label = os.path.splitext(os.path.basename(image_path))[0]\n","    known_encodings.append(encoding)\n","    labels.append(label)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Train a face recognition model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_recognition_model = face_recognition.face_distance(known_encodings, labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Save the trained model for later use"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_recognition_model.save(\"face_recognition_model.pkl\")\n","# Techniques for face identification and verification:\n","# For face identification and verification, you can use techniques like k-Nearest Neighbors (k-NN) or distance-based algorithms. Here's an example using the face_recognition library:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import face_recognition"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_recognition_model = face_recognition.face_distance.load(\"face_recognition_model.pkl\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Identify a face"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def identify_face(input_image):\n","    input_encoding = face_recognition.face_encodings(input_image)[0]  # Assuming a single face in the input image\n","    \n","    # Compare the face encoding with the known encodings\n","    distances = face_recognition.face_distance(face_recognition_model, input_encoding)\n","    min_distance_index = np.argmin(distances)\n","    identified_label = labels[min_distance_index]\n","    \n","    return identified_label"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Verify a face"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def verify_face(input_image, claimed_identity):\n","    input_encoding = face_recognition.face_encodings(input_image)[0]  # Assuming a single face in the input image\n","    \n","    # Compare the face encoding with the known encodings\n","    distances = face_recognition.face_distance(face_recognition_model, input_encoding)\n","    min_distance = np.min(distances)\n","    \n","    # Set a threshold for verification\n","    threshold = 0.6\n","    \n","    if min_distance <= threshold:\n","        return claimed_identity\n","    else:\n","        return \"Verification failed\"\n","\t\t\n","\t\t\n","# Evaluating the performance of the face recognition system, including metrics like accuracy, precision, and recall:\n","# To evaluate the performance of a face recognition system, you can calculate various metrics:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Function to evaluate the face recognition system"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_system():\n","    true_positives = 0\n","    true_negatives = 0\n","    false_positives = 0\n","    false_negatives = 0\n","    for image_path in image_paths:\n","        image = face_recognition.load_image_file(image_path)\n","        label = os.path.splitext(os.path.basename(image_path))[0]\n","\n","        # Identify the face\n","        identified_label = identify_face(image)\n","\n","        # Calculate metrics\n","        if label == identified_label:\n","            if label == claimed_identity:\n","                true_positives += 1\n","            else:\n","                true_negatives += 1\n","        else:\n","            if label == claimed_identity:\n","                false_negatives += 1\n","            else:\n","                false_positives += 1\n","\n","    # Calculate accuracy, precision, and recall\n","    accuracy = (true_positives + true_negatives) / len(image_paths)\n","    precision = true_positives / (true_positives + false_positives)\n","    recall = true_positives / (true_positives + false_negatives)\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Precision:\", precision)\n","    print(\"Recall:\", recall)\n","\t\n","# In this example, the evaluate_system() function compares the identified labels with the true labels and calculates metrics such as accuracy, precision, and recall."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Note: The specific implementation and choice of metrics may vary based on your requirements and the chosen face recognition library or model."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2. Revision of numpy\n","Refer to Level 1 - Session 1 & 2 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 3. Revision of Open CV\n","Refer to Level 1 - Session 3"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4. Revision of pandas\n","\n","Refer to Level 1 - Session 4"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5. CSV in Data Analysis"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["What is CSV (Comma-Separated Values)?\n","CSV (Comma-Separated Values) is a plain-text file format commonly used for storing and exchanging tabular data. It uses commas to separate values within each row and newline characters to separate rows. CSV files are simple and widely supported, making them a popular choice for data storage and exchange."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Structure and characteristics of CSV files:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Each row represents a data record, and each column represents a data field.\n","Values within each row are separated by commas.\n","The first row often contains column headers.\n","CSV files are plain text files and can be opened with any text editor.\n","CSV files have a flat structure and do not support nested or hierarchical data.\n","Advantages and common use cases of CSV in data analysis:\n","Advantages:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CSV files are human-readable and platform-independent.\n","They can be easily created, edited, and processed using various software tools.\n","CSV files have a small file size compared to other file formats like Excel.\n","They are widely supported by programming languages and data analysis libraries.\n","Common use cases:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Importing and exporting data between different software applications and databases.\n","Storing and sharing structured data in a simple and portable format.\n","Conducting data analysis and exploratory data analysis (EDA).\n","Creating datasets for machine learning and statistical modeling.\n","Reading CSV files using built-in Python libraries (e.g., csv module, pandas library):\n","Reading CSV using the csv module:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Writing from lists using the csv module:"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["data = [['Name', 'Age'], ['John', 25], ['Alice', 30], ['Bob', 35]]"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["with open('Images/new.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(data)\n","# Writing from a pandas DataFrame:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<hr>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":2}
